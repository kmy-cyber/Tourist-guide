"""
Agente especializado en interacci칩n con modelos de lenguaje.
"""
from typing import Dict, Any, Optional
from .base_agent import BaseAgent
from .interfaces import ILLMAgent, AgentContext, AgentType
from ..llm import LLM

class LLMAgent(BaseAgent, ILLMAgent):
    """Agente que maneja la generaci칩n de respuestas con LLM"""
    
    def __init__(self):
        """Inicializa el agente LLM"""
        super().__init__(AgentType.LLM)
        self.llm = LLM()
        
    async def process(self, context: AgentContext) -> AgentContext:
        """
        Procesa el contexto para generar una respuesta.
        
        Args:
            context: Contexto actual
            
        Returns:
            Contexto actualizado con la respuesta generada
        """
        try:
            # Construir prompt del sistema
            system_prompt = self.build_system_prompt(context)
            
            # Generar respuesta
            response = await self.generate_response(
                system_prompt=system_prompt,
                user_prompt=context.query,
                context=context.metadata
            )
            
            context.response = response
            self.update_context_confidence(context, 0.8 if response else 0.3)
            return context
            
        except Exception as e:
            self.set_error(context, f"Error generating response: {str(e)}")
            return context
            
    def build_system_prompt(self, context: AgentContext) -> str:
        """
        Construye el prompt del sistema con toda la informaci칩n disponible.
        
        Args:
            context: Contexto actual
            
        Returns:
            Prompt del sistema formateado
        """
        prompt_parts = [
            "Eres un gu칤a tur칤stico experto en Cuba.",
            "Usa la siguiente informaci칩n verificada como referencia:"
        ]

        if user_context := context.metadata.get("user_context"):
            user_profile = user_context.get("profile", {})
            user_name = user_profile.get("name")
            
            if user_name:
                prompt_parts.append(f"\nEl usuario se llama {user_name}. Dir칤gete a 칠l por su nombre de manera natural.")
            
            # A침adir intereses del usuario
            interests = user_context.get("interests", [])
            if interests:
                interests_text = ", ".join(interests[:4])  # Top 4 intereses
                prompt_parts.append(f"Sus principales intereses son: {interests_text}.")
            
            # A침adir ubicaciones que ha mencionado antes
            mentioned_locations = user_context.get("mentioned_locations", [])
            if mentioned_locations:
                locations_text = ", ".join(mentioned_locations[-3:])  # 칔ltimas 3
                prompt_parts.append(f"Ha preguntado anteriormente sobre: {locations_text}.")
            
            # A침adir contador de interacciones
            interaction_count = user_profile.get("interaction_count", 0)
            if interaction_count > 1:
                if interaction_count == 2:
                    prompt_parts.append("Esta es su segunda consulta contigo.")
                elif interaction_count <= 5:
                    prompt_parts.append(f"Ya han tenido {interaction_count} conversaciones.")
                else:
                    prompt_parts.append("Es un usuario frecuente, personaliza m치s tu respuesta.")
        
        prompt_parts.append("\nUsa la siguiente informaci칩n verificada como referencia para tu respuesta:")
        
        
        # A침adir informaci칩n de conocimiento
        if knowledge := context.metadata.get("knowledge"):
            prompt_parts.append("\nInformaci칩n disponible:")
            for info in knowledge:
                if isinstance(info, dict):
                    data = info.get("data", {})
                    prompt_parts.append(f"""
- {data.get('name', 'Lugar')} ({data.get('type', 'atracci칩n')}):
  {data.get('description', 'No hay descripci칩n disponible')}
""")
        
        # A침adir informaci칩n del clima
        if context.weather_info:
            prompt_parts.append("\nInformaci칩n del clima:")
            for city, weather in context.weather_info.items():
                prompt_parts.append(f"\n- {city}: {weather.get('report', '')}")
        
        # A침adir instrucciones espec칤ficas
        prompt_parts.extend([
            "\n游늶 INSTRUCCIONES:",
            "1. Proporciona informaci칩n precisa y relevante sobre Cuba",
            "2. Incluye el clima en tus recomendaciones si est치 disponible",
            "3. Menciona lugares espec칤ficos cuando sea posible",
            "4. Mant칠n un tono amigable, profesional y personalizado",
            "5. Si el usuario dice su nombre, recu칠rdalo para futuras interacciones",
            "6. Adapta tu respuesta seg칰n sus intereses y consultas anteriores",
            "7. Si es su primera vez, dale una bienvenida especial a Cuba",
            "8. No menciones ni hagas referencia a ning칰n lugar que no se haya pasado en la Informaci칩n disponible"
        ])
        
        return "\n".join(prompt_parts)
        
    async def generate_response(
        self,
        system_prompt: str,
        user_prompt: str,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Genera una respuesta usando el modelo de lenguaje.
        
        Args:
            system_prompt: Prompt del sistema
            user_prompt: Prompt del usuario
            context: Contexto adicional
            
        Returns:
            Respuesta generada
        """
        return await self.llm.generate_response(system_prompt, user_prompt)
